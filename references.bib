@article{Sinha2018,
   abstract = {This paper presents a new direction for the visual question answering task. Given an image with a simple linear algebraic equation system and a question in natural language based on the variables in the equations, we propose an end-to-end deep learning model that produces accurate answers to questions pertaining to the value of the variables and other related questions. Modeling the problem of solving simple linear equations as a VQA task makes it interesting as the system now requires three kinds of understanding a) visual understanding to recognize digits, variables, operators and equal sign b) conceptual understanding of the symbolic meanings of coefficients' constants, variables, operators and equality and c) high level understanding of the interaction between the image and the questions in order to accurately answer them. We also create an open-source dataset for the same and compare the performance of our model with different baselines.},
   author = {Abhishek Sinha and Kumar Ayush},
   doi = {10.1109/ICIP.2018.8451353},
   isbn = {9781479970612},
   issn = {15224880},
   journal = {Proceedings - International Conference on Image Processing, ICIP},
   keywords = {Deep Learning,Linear equations,Mathematical Reasoning,Visual Question Answering},
   month = {8},
   pages = {4028-4032},
   publisher = {IEEE Computer Society},
   title = {Towards Mathematical Reasoning: A Multimodal Deep Learning Approach},
   year = {2018},
}
@article{Lu2023,
   abstract = {Large Language Models (LLMs) and Large Multimodal Models (LMMs) exhibit impressive problem-solving skills in many tasks and domains, but their ability in mathematical reasoning in visual contexts has not been systematically studied. To bridge this gap, we present MathVista, a benchmark designed to combine challenges from diverse mathematical and visual tasks. It consists of 6,141 examples, derived from 28 existing multimodal datasets involving mathematics and 3 newly created datasets (i.e., IQTest, FunctionQA, and PaperQA). Completing these tasks requires fine-grained, deep visual understanding and compositional reasoning, which all state-of-the-art foundation models find challenging. With MathVista, we have conducted a comprehensive, quantitative evaluation of 12 prominent foundation models. The best-performing GPT-4V model achieves an overall accuracy of 49.9%, substantially outperforming Bard, the second-best performer, by 15.1%. Our in-depth analysis reveals that the superiority of GPT-4V is mainly attributed to its enhanced visual perception and mathematical reasoning. However, GPT-4V still falls short of human performance by 10.4%, as it often struggles to understand complex figures and perform rigorous reasoning. This significant gap underscores the critical role that MathVista will play in the development of general-purpose AI agents capable of tackling mathematically intensive and visually rich real-world tasks. We further explore the new ability of self-verification, the application of self-consistency, and the interactive chatbot capabilities of GPT-4V, highlighting its promising potential for future research. The project is available at https://mathvista.github.io/.},
   author = {Pan Lu and Hritik Bansal and Tony Xia and Jiacheng Liu and Chunyuan Li and Hannaneh Hajishirzi and Hao Cheng and Kai-Wei Chang and Michel Galley and Jianfeng Gao},
   month = {10},
   title = {MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts},
   url = {https://arxiv.org/abs/2310.02255v3},
   year = {2023},
}
@article{Baral2023,
   abstract = {Teachers often rely on the use of a range of open-ended problems to assess students' understanding of mathematical concepts. Beyond traditional conceptions of student open-ended work, commonly in the form of textual short-answer or essay responses, the use of figures, tables, number lines, graphs, and pictographs are other examples of open-ended work common in mathematics. While recent developments in areas of natural language processing and machine learning have led to automated methods to score student open-ended work, these methods have largely been limited to textual answers. Several computer-based learning systems allow students to take pictures of hand-written work and include such images within their answers to open-ended questions. With that, however, there are few-to-no existing solutions that support the auto-scoring of student hand-written or drawn answers to questions. In this work, we build upon an existing method for auto-scoring textual student answers and explore the},
   author = {Sami Baral and Anthony Botelho and Abhishek Santhanam and Ashish Gurung and Li Cheng and Neil Heffernan},
   doi = {10.5281/zenodo.8115645},
   journal = {International Educational Data Mining Society},
   keywords = {Artificial Intelligence,Computer Assisted Testing,Computer Software,Freehand Drawing,Handwriting,Learning Management Systems,Mathematical Concepts,Mathematics Instruction,Mathematics Tests,Natural Language Processing,Problem Solving,Responses,Scoring,Test Format},
   publisher = {International Educational Data Mining Society. e-mail: admin@educationaldatamining.org; Web site: https://educationaldatamining.org/conferences/},
   title = {Auto-Scoring Student Responses with Images in Mathematics.},
   url = {https://doi.org/10.5281/zenodo.8115645},
   year = {2023},
}
@misc{,
   abstract = {Multimodal numerical reasoning, the ability to reason with and integrate information across multiple modalities, has become an increasingly important area of research in both natural language processing (NLP) and computer vision (CV) domains. Multimodal numerical reasoning is designed to extract information from multiple input modalities, such as text, image, etc., and merge them into a comprehensive conclusion. In this survey, we review and provide an overview of the recent advancements in multimodal numerical reasoning, including datasets,evaluation metrics and methods. In particular, we focus on the emerging capabilities of large language models (LLMs) in out-of-the-box tasks of arithmetic, common sense, and symbolic reasoning.While we conducted experiments on GPT-3.5 turbo's mathematical information extraction for a single modality limited by the openness of model functions.we also outline some of the remaining limitations and future research directions in this field, including the need for more comprehensive benchmarks and the development of models that can reason with more complex and diverse modalities.},
   author = {Cvpr #},
   month = {6},
   title = {A Survey for Multimodal Mathematical Reasoning},
   year = {2023},
}
@article{Sakshi2023,
   abstract = {Context: Although recognition works on mathematical expressions have been explored for four decades, the current literature and trends are varied and frequently influenced by distinct emerging methods and technology. This situation instigates the necessity of an organized review to provide heedful insight into research trends and patterns currently prevailing in the domain of mathematical expression recognition (MER). Objective: To identify and associate (semantic mapping) the leading research zones, core research areas, and research trends steering in the MER domain. Identifying prominent recognition models based on extracted research areas. To develop the development chart from extracted research trends for directing the future works in this direction. Method: A manual and automatic search has been performed across the reputed digital libraries for corpus formation. The formulated corpus is used for topic modeling, and Latent Dirichlet Allocation is deployed for information modeling for achieving defined objectives. Result: The corpus of 325 research papers published from 1967 to 2021 has been processed using LDA. The five major research areas and ten research trends are identified. Leading research area is “Segmentation and Classification Procedures”, and the trend with the highest related publications is “Contextual and Graph-based recognition”. “Attention and Deep Networks” has emerged as the newborn trend, and the identified newborn, young, and matured trends impetrate more exploration from the MER research community.},
   author = {Sakshi and Vinay Kukreja},
   doi = {10.1016/J.ESWA.2022.119028},
   issn = {0957-4174},
   journal = {Expert Systems with Applications},
   keywords = {Latent dirichlet allocation,Mathematical expressions,Pattern recognition,Research trends,Topic modelling},
   month = {3},
   pages = {119028},
   publisher = {Pergamon},
   title = {Recent trends in mathematical expressions recognition: An LDA-based analysis},
   volume = {213},
   year = {2023},
}
@article{Lan2015,
   abstract = {While computer and communication technologies have provided effective means to scale up many aspects of education, the submission and grading of assessments such as homework assignments and tests remains a weak link. In this paper, we study the problem of automatically grading the kinds of open response mathematical questions that figure prominently in STEM (science, technology, engineering, and mathematics) courses. Our data-driven framework for mathematical language processing (MLP) leverages solution data from a large number of learners to evaluate the correctness of their solutions, assign partial-credit scores, and provide feedback to each learner on the likely locations of any errors. MLP takes inspiration from the success of natural language processing for text data and comprises three main steps. First, we convert each solution to an open response mathematical question into a series of numerical features. Second, we cluster the features from several solutions to uncover the structures of correct, partially correct, and incorrect solutions. We develop two different clustering approaches, one that leverages generic clustering algorithms and one based on Bayesian nonparametrics. Third, we automatically grade the remaining (potentially large number of) solutions based on their assigned cluster and one instructor-provided grade per cluster. As a bonus, we can track the cluster assignment of each step of a multistep solution and determine when it departs from a cluster of correct solutions, which enables us to indicate the likely locations of errors to learners. We test and validate MLP on real-world MOOC data to demonstrate how it can substantially reduce the human effort required in large-scale educational platforms.},
   author = {Andrew S. Lan and Divyanshu Vats and Andrew E. Waters and Richard G. Baraniuk},
   journal = {L@S 2015 - 2nd ACM Conference on Learning at Scale},
   keywords = {Assessment,Automatic grading,Bayesian nonparametrics,Clustering,Feedback,Machine learning,Mathematical language processing},
   month = {1},
   pages = {167-176},
   publisher = {Association for Computing Machinery},
   title = {Mathematical Language Processing: Automatic Grading and Feedback for Open Response Mathematical Questions},
   url = {http://arxiv.org/abs/1501.04346},
   year = {2015},
}
@article{Meadows2022,
   abstract = {Informal mathematical text underpins real-world quantitative reasoning and communication. Developing sophisticated methods of retrieval and abstraction from this dual modality is crucial in the pursuit of the vision of automating discovery in quantitative science and mathematics. We track the development of informal mathematical language processing approaches across five strategic sub-areas in recent years, highlighting the prevailing successful methodological elements along with existing limitations.},
   author = {Jordan Meadows and Andre Freitas},
   month = {5},
   title = {A Survey in Mathematical Language Processing},
   url = {https://arxiv.org/abs/2205.15231v1},
   year = {2022},
}
@article{Meadows2023,
   abstract = {Automating discovery in mathematics and science will require sophisticated methods of information extraction and abstract reason-ing, including models that can convincingly process relationships between mathematical elements and natural language, to pro-duce problem solutions of real-world value. We analyze mathematical language processing methods across five strategic sub-areas (identifier-definition extraction, formula re-trieval, natural language premise selection, math word problem solving, and informal theorem proving) from recent years, highlighting prevailing methodologies, existing limitations, overarching trends, and promising avenues for future research.},
   author = {Jordan Meadows and André Freitas},
   doi = {10.1162/TACL_A_00594/117587/INTRODUCTION-TO-MATHEMATICAL-LANGUAGE-PROCESSING},
   issn = {2307387X},
   journal = {Transactions of the Association for Computational Linguistics},
   month = {12},
   pages = {1162-1184},
   publisher = {MIT Press Journals},
   title = {Introduction to Mathematical Language Processing: Informal Proofs, Word Problems, and Supporting Tasks},
   volume = {11},
   url = {https://dx.doi.org/10.1162/tacl_a_00594},
   year = {2023},
}
@article{,
   author = {Deborah Ferreira},
   title = {MATHEMATICAL LANGUAGE PROCESSING: DEEP LEARNING REPRESENTATIONS AND INFERENCE OVER MATHEMATICAL TEXT A THESIS SUBMITTED TO THE UNIVERSITY OF MANCHESTER FOR THE DEGREE OF DOCTOR OF PHILOSOPHY IN THE FACULTY OF ENGINEERING AND PHYSICAL SCIENCES 2022},
}
@article{,
   abstract = {The use of computer-based systems in classrooms has provided teachers with new opportunities in delivering content to students, supplementing instruction, and assessing student knowledge and comprehension. Among the largest benefits of these systems is their ability to provide students with feedback on their work and also report student performance and progress to their teacher. While computer-based systems can automatically assess student answers to a range of question types, a limitation faced by many systems is in regard to open-ended problems. Many systems are either unable to provide support for open-ended problems, relying on the teacher to grade them manually, or avoid such question types entirely. Due to recent advancements in natural language processing methods, the automation of essay grading has made notable strides. However, much of this research has pertained to domains outside of mathematics, where the use of open-ended problems can be used by teachers to assess students' understanding of mathematical concepts beyond what is possible on other types of problems. This research explores the viability and challenges of developing automated graders of open-ended student responses in mathematics. We further explore how the scale of available data impacts model performance. Focusing on content delivered through the ASSISTments online learning platform, we present a set of analyses pertaining to the development and evaluation of models to predict teacher-assigned grades for student open responses. CCS CONCEPTS • Computing methodologies → Natural language processing ; Machine learning approaches.},
   author = {John A Erickson and Anthony F Botelho and Steven Mcateer and Ashvini Varatharaj and Neil T Heffernan},
   city = {New York, NY, USA},
   doi = {10.1145/3375462},
   isbn = {9781450377126},
   journal = {Proceedings of the Tenth International Conference on Learning Analytics & Knowledge},
   keywords = {automatic grading,natural language processing,open responses},
   publisher = {ACM},
   title = {The Automated Grading of Student Open Responses in Mathematics ACM Reference Format},
   url = {https://doi.org/10.1145/3375462.3375523},
}
@article{,
   abstract = {Open-ended questions in mathematics are commonly used by teachers to monitor and assess students' deeper conceptual understanding of content. Student answers to these types of questions often exhibit a combination of language, drawn diagrams and tables, and mathematical formulas and expressions that supply teachers with insight into the processes and strategies adopted by students in formulating their responses. While these student responses help to inform teachers on their students' progress and understanding , the amount of variation in these responses can make it difficult and time-consuming for teachers to manually read, assess, and provide feedback to student work. For this reason , there has been a growing body of research in developing AI-powered tools to support teachers in this task. This work seeks to build upon this prior research by introducing a model that is designed to help automate the assessment of student responses to open-ended questions in mathematics through sentence-level semantic representations. We find that this model outperforms previously-published benchmarks across three different metrics. With this model, we conduct an error analysis to examine characteristics of student responses that may be considered to further improve the method.},
   author = {Sami Baral and Anthony F Botelho and John A Erickson and Priyanka Benachamardi and Neil T Heffernan},
   keywords = {Automated scoring,Mathematics,Natural Language Pro-cessing,Open responses,Sentence-BERT},
   title = {Improving Automated Scoring of Student Open Responses in Mathematics},
   url = {https://educationaldatamining.org/edm2021/},
}
@article{,
   abstract = {Automatic short answer grading is an important research direction in the exploration of how to use artificial intelligence (AI)-based tools to improve education. Current state-of-the-art approaches use neural language models to create vector-ized representations of students responses, followed by clas-sifiers to predict the score. However, these approaches have several key limitations, including i) they use pre-trained language models that are not well-adapted to educational subject domains and/or student-generated text and ii) they almost always train one model per question, ignoring the linkage across question and result in a significant model storage problem due to the size of advanced language models. In this paper, we study the problem of automatic short answer grading for students' responses to math questions and propose a novel framework for this task. First, we use MathBERT, a variant of the popular language model BERT adapted to mathematical content, as our base model and fine-tune it on the downstream task of student response grading. Second , we use an in-context learning approach that provides scoring examples as input to the language model to provide additional context information and promote generalization to previously unseen questions. We evaluate our framework on a real-world dataset of student responses to open-ended math questions and show that our framework (often significantly) outperform existing approaches, especially for new questions that are not seen during training.},
   author = {Mengxue Zhang and Massachusetts Amherst and Sami Baral and Neil Heffernan and Andrew Lan},
   keywords = {Automated scoring,Math grading,Short-answer scoring},
   title = {Automatic Short Math Answer Grading via In-context Meta-learning},
   url = {https://github.com/kikumaru818/meta_math_scoring},
}
@article{Costa2021,
   abstract = {Handwritten mathematical expression recognition (HMER) is a challenging task due to factors such as ambiguity, variety of writing styles, and complexity of two-dimensional writing. In this paper, we identify challenges in HMER applications through experiments that simulate real scenarios that go far beyond the usual cases found in literature: variations on luminance; different stroke width, inclination and color; different background pattern; and partially shaded images. The results of state-of-the-art methods (as TAP and Dense-WAP) and a commercial tool (MathPix) are analyzed, using the CROHME 2016 database. We proved that, although the area has had a lot of improvement in recent years, there are still issues to overcome.},
   author = {Daniela S. Costa and Carlos A.B. Mello and Marcelo D'Amorim},
   doi = {10.1145/3469096.3474936},
   isbn = {9781450385961},
   journal = {DocEng 2021 - Proceedings of the 2021 ACM Symposium on Document Engineering},
   keywords = {deep learning,experimentation,handwritten mathematical expression recognition},
   month = {8},
   publisher = {Association for Computing Machinery, Inc},
   title = {A comparative study on methods and tools for handwritten mathematical expression recognition},
   url = {https://dl.acm.org/doi/10.1145/3469096.3474936},
   year = {2021},
}
@article{Kortemeyer2023,
   abstract = {Solving problems is crucial for learning physics, and not only final solutions but also their derivations are important. Grading these derivations is labor intensive, as it generally involves human evaluation of handwritten work. AI tools have not been an alternative, since even for short answers, they needed specific training for each problem or set of problems. Extensively pretrained AI systems offer a potentially universal grading solution without this specific training. This feasibility study explores an AI-assisted workflow to grade handwritten physics derivations using MathPix and GPT-4. We were able to successfully scan handwritten solution paths and achieved an R-squared of 0.84 compared to human graders on a synthetic dataset. The proposed workflow appears promising for formative feedback, but for final evaluations, it would best be used to assist human graders.},
   author = {Gerd Kortemeyer},
   doi = {10.1103/PHYSREVPHYSEDUCRES.19.020163/FIGURES/14/MEDIUM},
   issn = {24699896},
   issue = {2},
   journal = {Physical Review Physics Education Research},
   keywords = {doi:10.1103/PhysRevPhysEducRes.19.020163 url:https://doi.org/10.1103/PhysRevPhysEducRes.19.020163},
   month = {7},
   pages = {020163},
   publisher = {American Physical Society},
   title = {Toward AI grading of student problem solutions in introductory physics: A feasibility study},
   volume = {19},
   url = {https://journals.aps.org/prper/abstract/10.1103/PhysRevPhysEducRes.19.020163},
   year = {2023},
}
@article{Iskandar2023,
   abstract = {Optical character recognition (OCR) is the conversion of printed or written text from a scanned document or image file into a machine-readable form to be used for data processing like editing. Handwriting has been a way of communication for centuries, but modern technology has made it easier with the introduction of modern computers. While people have adapted to typing out words using a keyboard, formulas and mathematical expressions requires additional add-ons installed in the word processor. The process can be time consuming and tedious. Therefore, an alternative method is proposed in this paper in which handwritten mathematical formulas are converted into computer readable text. Horizontal and vertical projection is used for segmentation while convolutional neural network for character recognition is used to increase the recognition accuracy. The proposed method was able to segment out handwritten mathematical equations from lined papers as well as extract out and identify each character written. The handwritten equation was then successfully converted to a digital format.},
   author = {Nasuha Iskandar and Wei Jen Chew and Swee King Phang},
   doi = {10.1088/1742-6596/2523/1/012014},
   isbn = {2523012014},
   issn = {1742-6596},
   issue = {1},
   journal = {Journal of Physics: Conference Series},
   keywords = {affordable,fast,flexible,open access,proceedings,template},
   month = {7},
   pages = {012014},
   publisher = {IOP Publishing},
   title = {The Application of Image Processing for Conversion of Handwritten Mathematical Expression},
   volume = {2523},
   url = {https://iopscience.iop.org/article/10.1088/1742-6596/2523/1/012014 https://iopscience.iop.org/article/10.1088/1742-6596/2523/1/012014/meta},
   year = {2023},
}
@article{Tang2024,
   abstract = {Handwritten mathematical expression recognition (HMER) has attracted extensive attention. Despite the significant progress achieved in recent years attributed to the development of deep learning approaches, HMER remains a challenge due to the complex spatial structure and variable writing styles. Encoder–decoder models with attention mechanism, which treats HMER as an image-to-sequence (i.e. LaTeX) generation task, have boosted the accuracy, but suffer from low interpretability in that the symbols are not segmented explicitly. Symbol segmentation is desired for facilitating post-processing and human interaction in real applications. In this paper, we formulate the mathematical expression as a graph and propose a Graph-Encoder-Transformer-Decoder (GETD) approach for HMER. For constructing the graph from input image, candidate symbols are first detected using an object detector and represented as the nodes of a graph, called symbol graph, and the edges of the graph encodes the between-symbol relationship. The spatial information is aggregated in a graph neural network (GNN), and a Transformer-based decoder is used to identify the symbol classes and structure from the graph. Experiments on public datasets demonstrate that our GETD model achieves competitive expression recognition performance while offering good interpretability compared with previous methods.},
   author = {Jia Man Tang and Hong Yu Guo and Jin Wen Wu and Fei Yin and Lin Lin Huang},
   doi = {10.1016/J.PATCOG.2023.110155},
   issn = {0031-3203},
   journal = {Pattern Recognition},
   keywords = {Graph Neural Network,Handwritten mathematical expression recognition,Symbol detection,Transformer},
   month = {4},
   pages = {110155},
   publisher = {Pergamon},
   title = {Offline handwritten mathematical expression recognition with graph encoder and transformer decoder},
   volume = {148},
   year = {2024},
}
@article{Mirkazemy2023,
   abstract = {In this paper, we propose a novel deep neural model for Mathematical Expression Recognition (MER). The proposed model uses encoder–decoder transformer architecture that is supported by additional pre/post-processing modules, to recognize the image of mathematical formula and convert it to a well-formed language. A novel pre-processing module based on domain prior knowledge is proposed to generate random pads around the formula's image to create more efficient feature maps and keeps all the encoder neurons active during the training process. Also, a new post-processing module is developed which uses a sliding window to extract additional position-based information from the feature map, that is proved to be useful in the recognition process. The recurrent decoder module uses the combination of feature maps and the additional position-based information, which takes advantage of a soft attention mechanism, to extract the formula context into the LaTeX well-formed language. Finally, a novel Reinforcement Learning (RL) module processes the decoder output and tunes its results by sending proper feedbacks to the previous steps. The experimental results on im2latex-100k benchmark dataset indicate that each devised pre/post-processing as well as the RL refinement module has a positive effect on the performance of the proposed model. The results also demonstrate the higher accuracy of the proposed model compared to the state-of-the-art methods.},
   author = {Abolfazl Mirkazemy and Peyman Adibi and Seyed Mohhamad Saied Ehsani and Alireza Darvishy and Hans Peter Hutter},
   doi = {10.1016/J.NEUNET.2023.08.045},
   issn = {0893-6080},
   journal = {Neural Networks},
   keywords = {Attention,Deep learning,Encoder–decoder​ architecture,Mathematical expression recognition,Scientific documents accessibility},
   month = {10},
   pages = {865-874},
   pmid = {37741068},
   publisher = {Pergamon},
   title = {Mathematical expression recognition using a new deep neural model},
   volume = {167},
   year = {2023},
}
@article{Li2023,
   abstract = {Handwritten mathematical expression recognition (HMER) is an essential task in the OCR community, which consists of two sub-tasks, i.e., symbol recognition and structure parsing. Modern literature treats HMER as a LaTeX sequence predicting problem that simultaneously recognizes symbols and parses the structures of MEs. Although deep learning-based HMER methods have been achieving promising results on public benchmarks, it is admitted that the misclassification error between visually similar symbols still prevents these approaches from more generalized scenes. In this paper, we try to solve this issue from three aspects. 1) We enhanced the feature extraction progress by introducing path signature features, which incorporates local writing details and global spatial information. 2) We developed a language model that uses contextual information to correct the symbols misclassified by vision-only-based recognition models. 3) We solved the misalignment problem in existing ensemble method by designing a dynamic time warping (DTW) based algorithm. By combining the above improvements, our method achieved state-of-the-art results on three CROHME benchmarks, outperforming previous methods by a large margin.},
   author = {Zhe Li and Xinyu Wang and Yuliang Liu and Lianwen Jin and Yichao Huang and Kai Ding},
   doi = {10.1109/TMM.2023.3260648},
   issn = {19410077},
   journal = {IEEE Transactions on Multimedia},
   keywords = {Handwritten mathematical expression recognition,dynamic time warping,ensemble,language model,path signature},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Improving Handwritten Mathematical Expression Recognition Via Similar Symbol Distinguishing},
   year = {2023},
}
@misc{,
   title = {hendrycks/math: The MATH Dataset (NeurIPS 2021)},
   url = {https://github.com/hendrycks/math},
}
@article{Xie2023,
   abstract = {This paper overviews the 7th edition of the Competition on Recognition of Handwritten Mathematical Expressions. ICDAR 2023 CROHME proposes three tasks with three different modalities: on-line, off-line and bimodal. 3905 new handwritten equations have been collected to propose new training, validation and test sets for the two modalities. The complete training set includes previous CROHME training set extented with complementary off-line (from OffRaSHME competition) and on-line samples (generated). The evaluation is conducted using the same protocol as the previous CROHME, allowing a fair comparison with previous results. This competition allows for the first time the comparison of the on-line and off-line systems on the same test set. Six participating teams have been evaluated. Finally the same team won all 3 tasks with more than 80% of expression recognition rate.},
   author = {Yejing Xie and Harold Mouchère and Foteini Simistira Liwicki and Sumit Rakesh and Rajkumar Saini and Masaki Nakagawa and Cuong Tuan Nguyen and Thanh Nghia Truong},
   doi = {10.1007/978-3-031-41679-8_33/TABLES/4},
   isbn = {9783031416781},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {bimodal,dataset,evaluation,handwriting recognition,mathematical expression recognition},
   pages = {553-565},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {ICDAR 2023 CROHME: Competition on Recognition of Handwritten Mathematical Expressions},
   volume = {14188 LNCS},
   url = {https://link.springer.com/chapter/10.1007/978-3-031-41679-8_33},
   year = {2023},
}
@article{Zhang2018,
   abstract = {Handwritten mathematical expression recognition is a challenging problem due to the complicated two-dimensional structures, ambiguous handwriting input and variant scales of handwritten math symbols. To settle this problem, recently we propose the attention based encoder-decoder model that recognizes mathematical expression images from two-dimensional layouts to one-dimensional LaTeX strings. In this study, we improve the encoder by employing densely connected convolutional networks as they can strengthen feature extraction and facilitate gradient propagation especially on a small training set. We also present a novel multi-scale attention model which is employed to deal with the recognition of math symbols in different scales and restore the fine-grained details dropped by pooling operations. Validated on the CROHME competition task, the proposed method significantly outperforms the state-of-the-art methods with an expression recognition accuracy of 52.8% on CROHME 2014 and 50.1% on CROHME 2016, by only using the official training dataset.},
   author = {Jianshu Zhang and Jun Du and Lirong Dai},
   doi = {10.1109/ICPR.2018.8546031},
   isbn = {9781538637883},
   issn = {10514651},
   journal = {Proceedings - International Conference on Pattern Recognition},
   month = {11},
   pages = {2245-2250},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Multi-Scale Attention with Dense Encoder for Handwritten Mathematical Expression Recognition},
   volume = {2018-August},
   year = {2018},
}
@article{Zhao2022,
   abstract = {The Transformer-based encoder-decoder architecture has recently made significant advances in recognizing handwritten mathematical expressions. However, the transformer model still suffers from the lack of coverage problem, making its expression recognition rate (ExpRate) inferior to its RNN counterpart. Coverage information, which records the alignment information of the past steps, has proven effective in the RNN models. In this paper, we propose CoMER, a model that adopts the coverage information in the transformer decoder. Specifically, we propose a novel Attention Refinement Module (ARM) to refine the attention weights with past alignment information without hurting its parallelism. Furthermore, we take coverage information to the extreme by proposing self-coverage and cross-coverage, which utilize the past alignment information from the current and previous layers. Experiments show that CoMER improves the ExpRate by 0.61%/2.09%/1.59% compared to the current state-of-the-art model, and reaches 59.33%/59.81%/62.97% on the CROHME 2014/2016/2019 test sets.},
   author = {Wenqi Zhao and Liangcai Gao},
   doi = {10.1007/978-3-031-19815-1_23},
   isbn = {9783031198144},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Alignment,Coverage,Encoder-decoder model,Handwritten mathematical expression recognition,Transformer},
   month = {7},
   pages = {392-408},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {CoMER: Modeling Coverage for Transformer-based Handwritten Mathematical Expression Recognition},
   volume = {13688 LNCS},
   url = {https://arxiv.org/abs/2207.04410v2},
   year = {2022},
}
@article{Le2019,
   abstract = {Recognition of Handwritten Mathematical Expressions (HMEs) is a challenging problem because of the ambiguity and complexity of two-dimensional handwriting. Moreover, the lack of large training data is a serious issue, especially for academic recognition systems. In this paper, we propose pattern generation strategies that generate shape and structural variations to improve the performance of recognition systems based on a small training set. For data generation, we employ the public databases: CROHME 2014 and 2016 of online HMEs. The first strategy employs local and global distortions to generate shape variations. The second strategy decomposes an online HME into sub-online HMEs to get more structural variations. The hybrid strategy combines both these strategies to maximize shape and structural variations. The generated online HMEs are converted to images for offline HME recognition. We tested our strategies in an end-to-end recognition system constructed from a recent deep learning model: Convolutional Neural Network and attention-based encoder-decoder. The results of experiments on the CROHME 2014 and 2016 databases demonstrate the superiority and effectiveness of our strategies: our hybrid strategy achieved classification rates of 48.78% and 45.60%, respectively, on these databases. These results are competitive compared to others reported in recent literature. Our generated datasets are openly available for research community and constitute a useful resource for the HME recognition research in future.},
   author = {Anh Duc Le and Bipin Indurkhya and Masaki Nakagawa},
   doi = {10.1016/j.patrec.2019.09.002},
   issn = {01678655},
   journal = {Pattern Recognition Letters},
   keywords = {data generation strategies,decomposition model,distortion model,end-to-end recognition system,handwritten mathematical expression},
   month = {1},
   pages = {255-262},
   publisher = {Elsevier B.V.},
   title = {Pattern Generation Strategies for Improving Recognition of Handwritten Mathematical Expressions},
   volume = {128},
   url = {https://arxiv.org/abs/1901.06763v1},
   year = {2019},
}
@misc{,
   title = {chungkwong/mathocr-tap: Offline handwritten mathematical expression recognition via stroke extraction and TAP},
   url = {https://github.com/chungkwong/mathocr-tap},
}
@misc{,
   title = {dprl@RIT},
   url = {https://www.cs.rit.edu/~dprl/old/CROHMELib_LgEval_Doc.html},
}
@misc{,
   title = {CROHME},
   url = {https://www.isical.ac.in/~crohme/CROHME_data.html},
}
@article{,
   author = {by Kelsey Leigh Von Tish},
   title = {Interpretation and Clustering of Handwritten Student Responses},
   year = {2012},
}
@article{Chaowicharat2023,
   abstract = {An automatic system that helps teachers and students verify the correctness of handwritten derivation in mathematics homework is proposed. The system acquires input image containing handwritten mathematical deri-vation. In our preliminary study, the system that comprises only mathematical expression recognition (MER) and computer algebra system (CAS) did not perform well due to high misrecognition rate. Therefore, our study focuses on fixing the misrecognized symbols by using symbols replacement and the surrounding information. If all the original mathematical expressions (MEs) in the derivation sequence are already equivalent, the derivation is marked as “correct”. Otherwise, the symbols with low recognition confidence will be replaced by other possible candidates to maximize the number of equivalent MEs in that derivation. If there is none of symbols replacement that makes every line equivalent, the derivation is marked as “incorrect”. The recursive expression tree comparison was applied to report the types of mistake for those problems marked as incorrect. Finally, the performance of the system was evaluated by the digitally generated dataset of 6,000 handwritten mathematical derivations. The results showed that the symbols replacement improve the F1-score of derivation step marking from 69.41 to 95.95 % for the addition/ subtraction dataset and from 61.45 to 89.95 % for the multiplication dataset when compared to the case of using raw recognized string without symbols replacement.},
   author = {Ekawat Chaowicharat and Natasha Dejdumrong},
   doi = {10.5755/j01.itc.52.1.32066},
   issn = {2335884X},
   issue = {1},
   journal = {Information Technology and Control},
   keywords = {Mathematical expression recognition,automatic homework grading,symbols replacement},
   month = {3},
   pages = {169-184},
   publisher = {Kauno Technologijos Universitetas},
   title = {A Step Toward an Automatic Handwritten Homework Grading System for Mathematics},
   volume = {52},
   year = {2023},
}
@article{Heska2021,
   author = {Vincenzo Heska},
   title = {Generating Synthetic Online Handwritten Mathematical Expressions from Markup Languages},
   year = {2021},
}
@misc{,
   title = {KaTeX – The fastest math typesetting library for the web},
   url = {https://katex.org/},
}
@article{Springstein2021,
   abstract = {The recognition of handwritten mathematical expressions in images and video frames is a difficult and unsolved problem yet. Deep convectional neural networks are basically a promising approach, but typically require a large amount of labeled training data. However, such a large training dataset does not exist for the task of handwritten formula recognition. In this paper, we introduce a system that creates a large set of synthesized training examples of mathematical expressions which are derived from LaTeX documents. For this purpose, we propose a novel attention-based generative adversarial network to translate rendered equations to handwritten formulas. The datasets generated by this approach contain hundreds of thousands of formulas, making it ideal for pretraining or the design of more complex models. We evaluate our synthesized dataset and the recognition approach on the CROHME 2014 benchmark dataset. Experimental results demonstrate the feasibility of the approach.},
   author = {Matthias Springstein and Eric Müller-Budack and Ralph Ewerth},
   doi = {10.1145/3463945.3469059},
   isbn = {9781450385305},
   journal = {MMPT 2021 - Proceedings of the 2021 Workshop on Multi-Modal Pre-Training for Multimedia Understanding},
   keywords = {datasets,formula recognition,generative adversarial network,• Applied computing → Optical character recognition KEYWORDS datasets,• Computing methodologies → Supervised learn-ing by classification},
   month = {8},
   pages = {46-54},
   publisher = {Association for Computing Machinery, Inc},
   title = {Unsupervised Training Data Generation of Handwritten Formulas using Generative Adversarial Networks with Self-Attention},
   url = {https://dl.acm.org/doi/10.1145/3463945.3469059},
   year = {2021},
}
@article{,
   abstract = {We further investigate the problem of recognizing handwritten mathematical expressions, which we also chose for our CS221 final project [3]. Being able to change handwritten expressions into L A T E X has applications for consumers and academics. While large amounts of work have been done for digit and character recognition [2] [10], much less progress has been made surrounding handwritten expression recognition. To the best of our knowledge, no papers have been published applying Convolutional Neural Networks (CNNs) to the task of handwritten expression recognition. We build an end-to-end system using our best CNN model to go from strokes to symbols to a L A T E X expression. We also compare our results to other systems; experimental evaluation suggests that CNNs are a powerful tool for handwritten mathematical expression recognition.},
   author = {Catherine Lu and Karanveer Mohan},
   title = {Recognition of Online Handwritten Mathematical Expressions Using Convolutional Neural Networks},
}
@misc{,
   title = {A Synthetic Dataset for Clustering Handwritten Math Expression TUAT (Dset_Mix) - TC-11},
   url = {https://tc11.cvc.uab.es/datasets/Dset_Mix_1},
}
@misc{,
   author = {V U Tran and Minh Khuong},
   title = {Clustering and user interface to assist in marking handwritten mathematical expressions 手書き数式解答の採点を支援するためのクラスタリング とユーザーインターフェイス},
}
@article{,
   abstract = {Humans are naturally capable of solving mathematical expressions, but machines lack the ability to comprehend an issue through a visual context. Computers are gradually becoming more advanced and catching up with the subtlety and inaccuracy of real life. The need for an automated system to check answer scripts of mathematical equations has become unparallel, especially for Bengali handwritten scripts. This study checks each line of the solution of a mathematical equation to evaluate its correctness using a deep learning approach. In contrast to earlier methods, this paper introduces a CNN architecture to verify the accuracy of a handwritten mathematical equation in addition to solving the problem. The model reads a handwritten equation and validates its mathematical symbols and operations. A dataset has been created to evaluate the models performance which is named "BHQED". The experimental result shows that the accuracy of the proposed CNN architecture is 92.25% and the recall is 90.65% on our solely created dataset. To further boost the performance, this study applies the pretrained ResNet18 model and substantially outperforms the CNN with an accuracy of 94.57% and recall of 93.69%.},
   author = {Tashhq Nahiyan Khan Khan and Rachita Dewanjee Dewanjee and Nushrat Jahan Shorna Shorna and Mejbah Ur Rahman Sowad Sowad and Md Tanvir Rouf Shawon Shawon and Tashfiq Nahiyan Khan and Rachita Dewanjee and Nushrat Jahan Shorna and Mejbah Ur Rahman Sowad and Md Tanvir Rouf Shawon},
   doi = {10.21203/rs.3.rs-2553612/v1},
   keywords = {CNN,Handwritten equation,Mathematical Equation,Mathematical Equation Keywords: Handwritten equation,ResNet18},
   title = {Evaluation of Bengali Handwritten Mathematical Equationusing Convolutional Neural Network Evaluation of Bengali Handwritten Mathematical Equation using Convolutional Neural Network},
   url = {https://doi.org/10.21203/rs.3.rs-2553612/v1},
   year = {2023},
}
@misc{,
   title = {Text to Handwriting Converter Online | 10015 Tools},
   url = {https://10015.io/tools/text-to-handwriting-converter},
}
@misc{,
   title = {federicomichelotto/CROHME},
   url = {https://github.com/federicomichelotto/CROHME/tree/master},
}
@article{Dong2022,
   abstract = {Offline handwritten mathematical expression recognition is a challenging optical character recognition (OCR) task due to various ambiguities of handwritten symbols and complicated two-dimensional structures. Recent work in this area usually constructs deeper and deeper neural networks trained with end-to-end approaches to improve the performance. However, the higher the complexity of the network, the more the computing resources and time required. To improve the performance without more computing requirements, we concentrate on the training data and the training strategy in this paper. We propose a data augmentation method which can generate synthetic samples with new LaTeX notations by only using the official training data of CROHME. Moreover, we propose a novel training strategy called Shuffled Multi-Round Training (SMRT) to regularize the model. With the generated data and the shuffled multi-round training strategy, we achieve the state-of-the-art result in expression accuracy, i.e., 59.74% and 61.57% on CROHME 2014 and 2016, respectively, by using attention-based encoder-decoder models for offline handwritten mathematical expression recognition.},
   author = {Lan Fang Dong and Han Chao Liu and Xin Ming Zhang},
   doi = {10.1007/S11390-021-0722-4/METRICS},
   issn = {18604749},
   issue = {6},
   journal = {Journal of Computer Science and Technology},
   keywords = {handwritten mathematical expression recognition,offline,synthetic data generation,training strategy},
   month = {12},
   pages = {1427-1443},
   publisher = {Springer},
   title = {Synthetic Data Generation and Shuffled Multi-Round Training Based Offline Handwritten Mathematical Expression Recognition},
   volume = {37},
   url = {https://link.springer.com/article/10.1007/s11390-021-0722-4},
   year = {2022},
}
